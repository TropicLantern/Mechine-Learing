What is Machine Learning?
Tom Mitchell provides a more modern definition: "A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, 
if its performance at tasks in T, as measured by P, improves with experience E."

experience E,task T,performance measure P

Example: playing checkers.
E = the experience of playing many games of checkers
T = the task of playing checkers.
P = the probability that the program will win the next game.
In general, any machine learning problem can be assigned to one of two broad classifications:
Supervised learning and Unsupervised learning.

Supervised learning
In supervised learning, we are given a data set and already know what our correct output should look like, 
having the idea that there is a relationship between the input and the output.Supervised learning problems are categorized into "regression" and "classification" problems. 
In a regression problem, we are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function. 
In a classification problem, we are instead trying to predict results in a discrete output. In other words, we are trying to map input variables into discrete categories. 

Example 1:
Given data about the size of houses on the real estate market, try to predict their price. Price as a function of size is a continuous output, so this is a regression problem.
We could turn this example into a classification problem by instead making our output about whether the house "sells for more or less than the asking price." 
Here we are classifying the houses based on price into two discrete categories.

Example 2:
(a) Regression - Given a picture of a person, we have to predict their age on the basis of the given picture
(b) Classification - Given a patient with a tumor, we have to predict whether the tumor is malignant or benign. 

right answers given

Regression:Predict continuous(for example,valued output such as "price")
Classification problem
Discrete valued,output(0 or 1......)

Unsupervised learning
clustering problem
Unsupervised learning allows us to approach problems with little or no idea what our results should look like. 
We can derive structure from data where we don't necessarily know the effect of the variables.
We can derive this structure by clustering the data based on relationships among the variables in the data.
With unsupervised learning there is no feedback based on the prediction results.
Example:
Clustering: Take a collection of 1,000,000 different genes, and find a way to automatically group these genes into groups that are somehow similar or related by different 
variables, such as lifespan, location, roles, and so on.
Non-clustering: The "Cocktail Party Algorithm", allows you to find structure in a chaotic environment. (i.e. identifying individual voices and music from a mesh of sounds 
at a cocktail party).

有监督学习与无监督学习的几大区别：
对比一 ： 有标签 vs 无标签
有监督的过程为先通过已知的训练样本（如已知输入和对应的输出）来训练，从而得到一个最优模型，再将这个模型应用在新的数据上，映射为输出结果。再经过这样的过程后，模型就有了预知能力。
无监督相比于有监督，没有训练的过程，而是直接拿数据进行建模分析，意味着这些都是要通过机器学习自行学习探索。比如我们去参观一个画展，我们对艺术一无所知，但是欣赏完多幅作品之后，我们也
能把它们分成不同的派别。比如哪些更朦胧一点，哪些更写实一些。即使我们不知道什么叫做朦胧派和写实派，但是至少我们能把他们分为两个类。
对比二 ： 分类 vs 聚类
有监督机器学习的核心是分类，无监督机器学习的核心是聚类（将数据集合分成由类似的对象组成的多个类）。有监督的工作是选择分类器和确定权值，无监督的工作是密度估计（寻找描述数据统计值），
这意味着无监督算法只要知道如何计算相似度就可以开始工作。
对比三 ： 同维 vs 降维
有监督的输入如果是n维，特征即被认定为n维，也即y=f(xi)或p(y|xi), i =n，通常不具有降维的能力。而无监督经常要参与深度学习，做特征提取，或者干脆采用层聚类或者项聚类，以减少数据特征的维
度。
对比四 ： 分类同时定性 vs 先聚类后定性
有监督的输出结果，也就是分好类的结果会被直接贴上标签，是好还是坏。也即分类分好了，标签也同时贴好了。类似于药店，采购回来药材，把对应的每一个药材放进贴着标签的药匣中。
无监督的结果只是一群一群的聚类，就像被混在一起的多种中药，一个外行要处理这堆药材，能做的只有把看上去一样的药材挑出来聚成很多个小堆。如果要进一步识别这些小堆，就需要一个
专业的医生的指导。因此，无监督属于先聚类后定性，有点类似于批处理。
对比五 ： 独立 vs 非独立
对于不同的场景，正负样本的分布可能会存在偏移（可能是大的偏移，也可能偏移比较小）。例如手动对数据做标注作为训练样本，并把样本画在特征空间中，发现线性非常好，然而在分类面，总有一些
混淆的数据样本。对这种现象的一个解释是，不管训练样本（有监督），还是待分类的数据（无监督），并不是所有数据都是相互独立分布的。或者说，数据和数据的分布之间存在联系。作为训练样本，大的
偏移很可能会给分类器带来很大的噪声，而对于无监督，情况就会好很多。可见，独立分布数据更适合有监督，非独立数据更适合无监督。
对比六 ： 不透明 vs 可解释性
由于有监督算法最后输出的是一个结果，或者标签。yes or no，一定是会有一个倾向。如果探究为什么这样，有监督会告诉你：因为我们给每个字段乘以了一个参数列[w1, w2, w3…wn]。你继续追问：为什么
是这个参数列？为什么第一个字段乘以了0.01而不是0.02？有监督会告诉你：这是我自己学习计算的！然后，就拒绝再回答你的任何问题。是的，有监督算法的分类原因是不具有可解释性的，或者说，是不透
明的，因为这些规则都是通过人为建模得出，及其并不能自行产生规则。所以，对于需要明确规则的场景，就很难应用。而无监督的聚类方式通常是有很好的解释性的，你问无监督，为什么把他们分成一类？
无监督会告诉你，它们有多少特征有多少的一致性，所以才被聚成一组，进一步可以讲这个特征组总结成规则。
对比七 ： DataVisor无监督独有的拓展性
试想这样一个n维模型，产出结果已经非常好，这时又增加了一维数据，变成了n+1维。那么，如果这是一个非常强的特征，足以将原来的分类或者聚类打散，一切可能需要从头再来，尤其是有监督，权重值几
乎会全部改变。而DataVisor开发的无监督算法，具有极强的扩展性，无论多加的这一维数据的权重有多高，都不影响原来的结果输出，原来的成果仍然可以保留，只需要对多增加的这一维数据做一次处理即
可。
